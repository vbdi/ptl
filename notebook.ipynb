{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccf3ea8f-b4b9-4b41-9d44-3162ee7d43d8",
   "metadata": {},
   "source": [
    "# Task-Agnostic Language Model Watermarking via High Entropy Passthrough Layers\n",
    "This is the notebook for reproducing the results of the \"Task-Agnostic Language Model Watermarking via High Entropy Passthrough Layers\" paper accepted for publication in AAAI2025.\n",
    "\n",
    "<p align=\"center\">\n",
    "<center>\n",
    "<img src=\"https://vbdai-notebooks.obs.cn-north-4.myhuaweicloud.com/ptl/cover.png\" alt=\"alt text\" width=\"1000\">\n",
    "</center>\n",
    "</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170e7ce0-6592-40fa-88fd-b082f29346c0",
   "metadata": {},
   "source": [
    "## Download and extract the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea37a7a-c48b-4a7d-8ba6-68e5197e992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://vbdai-notebooks.obs.cn-north-4.myhuaweicloud.com/ptl/code.zip \n",
    "!unzip -qo code.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590d4096-541f-4c23-83fb-de364ae4fe0b",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "To use this package, please install the following dependencies using your\n",
    "favourite package manager:\n",
    "```\n",
    "torch\n",
    "datasets\n",
    "transformers\n",
    "scikit-learn\n",
    "scipy\n",
    "pandas\n",
    "numpy\n",
    "safetensors\n",
    "matplotlib\n",
    "ipython\n",
    "tqdm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60151634-8c43-43c4-8fc1-dfee2607e0e7",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "First download the required models and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732b4b03-c090-40d2-90b6-480e027e7a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod u+x download.sh\n",
    "!./download.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54170905-df6d-47b2-9e85-4492156d0287",
   "metadata": {},
   "source": [
    "This may take a while as both the dataset and model are very large.\n",
    "\n",
    "To watermark a Bert Passthrough model, use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1b38a6-6dad-4f3a-9308-161fff68eaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python watermark_passthrough.py --dataset_name=processed_book_corpus_full --max_steps=10000 --eval_steps=2000 --eval_beginning=False --run_name=working-bert-passthrough-2468-layer-10k-steps-train --watermark_layers=\"1 3 5 7 9\" --watermark_multipliers=\"1 1 1 1 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1254c29-ad21-42f2-b936-a2ef7c0962a3",
   "metadata": {},
   "source": [
    "Note: GPU training is strongly recommended. \n",
    "\n",
    "## Weights & Biases\n",
    "\n",
    "This package uses Weights & Biases to track training and evaluation metrics.\n",
    "You can get setup on Weights & Biases at: https://docs.wandb.ai/quickstart"
   ]
  }
 ],
 "metadata": {
  "AIGalleryInfo": {
   "item_id": "58b799a0-5cfc-4c2e-8b9b-440bb2315264"
  },
  "flavorInfo": {
   "architecture": "X86_64",
   "category": "GPU"
  },
  "imageInfo": {
   "id": "e1a07296-22a8-4f05-8bc8-e936c8e54099",
   "name": "pytorch1.4-cuda10.1-cudnn7-ubuntu18.04"
  },
  "kernelspec": {
   "display_name": "PyTorch-1.4",
   "language": "python",
   "name": "pytorch-1.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
